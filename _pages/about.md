---
layout: about
title: about
permalink: /
subtitle: 

profile:
  align: right
  image: face2.jpg
  image_circular: false # crops the image to make it circular
  more_info: >

news: true # includes a list of news items
latest_posts: false # includes a list of the newest posts
selected_papers: false # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page
---

Hi! I am a Ph.D student at [Seoul National University](http://milab.snu.ac.kr/research.html). I am fortunate to be advised by Prof. [Kyomin Jung](http://milab.snu.ac.kr/kjung/index.html). Previously, I received B.E. degrees from [KAIST](). I have also interned at NAVER AI LAB for controlled text generation, advised by [Hwaran Lee](https://hwaranlee.github.io/).

In my Ph.D. course, my research question is as follows: *"How can we **guarantee generations** that are [aligned with personalized preferences]() and [controlled under hard constraints]() while still [preserving pre-aligned general preferences]()?"* While novel training methods might offer a potential solution, I believe that [controlling the generation at the decoding-time]() is a more suitable approach for practical, real-world applications. This path presents significant challenges. We need to understand both the theoretical issues and the empirical effects of adjusting pre-aligned models to accommodate new personal values or hard constraints. Based on this fundamental understanding, I must investigate how to manipulate the distribution at the decoding-time to obtain the desired generations. Although it looks deeply challenging, I am enjoying this journey and am looking forward to the new insights it will bring.ðŸ˜Ž
