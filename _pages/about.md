---
layout: about
title: about
permalink: /
subtitle: 

profile:
  align: right
  image: face2.jpg
  image_circular: false # crops the image to make it circular
  more_info: >

news: true # includes a list of news items
latest_posts: false # includes a list of the newest posts
selected_papers: false # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page
---

Hi! I am a Ph.D student at **Seoul National University** advised by Prof. [Kyomin Jung](http://milab.snu.ac.kr/publication.html) and a student researcher at **<span style="color:#4285F4;">G</span><span style="color:#EA4335;">o</span><span style="color:#FBBC05;">o</span><span style="color:#4285F4;">g</span><span style="color:#34A853;">l</span><span style="color:#EA4335;">e</span>**. I also have also interned at <a href="https://lawzero.org/en" style="color:green;">LawZero</a> and <a href='https://europe.naverlabs.com/' style="color:blue;">NAVER Labs Europe </a> for **Safe Alignment in LLMs**.

<!-- My Ph.D. research primarily focuses on ***Controlled Generation*** from Large Language Models. More specifically, how can we control generations that are 1) [guaranteed to strictly satisfy essential constraints (e.g. safety guarantee)](), 2) aligned with [personal preferences](), and 3) still [preserving pre-aligned general preferences]()? As a practical and impactful solution for challenges, I strongly believe that harmony **between training-time methods** and **inference-time methods** is essential. Although it looks deeply challenging, I am enjoying this journey and looking forward to the new insights it will bring. ðŸ˜Ž -->

